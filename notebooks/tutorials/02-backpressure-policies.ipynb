{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a720d16f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ebe1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "jupyter:\n",
    "  jupytext:\n",
    "    text_representation:\n",
    "      extension: .py\n",
    "      format_name: light\n",
    "      format_version: '1.5'\n",
    "      jupytext_version: 1.17.2\n",
    "  kernelspec:\n",
    "    display_name: Python 3\n",
    "    name: python3\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01d20f7",
   "metadata": {},
   "source": [
    "# Backpressure Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfb487d",
   "metadata": {},
   "source": [
    "This notebook demonstrates the different backpressure policies available in Meridian Runtime. Backpressure is a critical mechanism for building robust and resilient dataflows. It allows a system to gracefully handle load spikes and prevent downstream components from being overwhelmed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09323905",
   "metadata": {},
   "source": [
    "## 1. Setup: Add Project to Python Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcdedcc",
   "metadata": {},
   "source": [
    "This cell adds the project's `src` directory to the Python path. This is necessary for the notebook to find and import the `meridian` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf577065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's 'src' directory to the Python path\n",
    "# This is necessary for the notebook to find the 'meridian' module\n",
    "# We assume the notebook is run from the 'notebooks/tutorials' directory.\n",
    "src_path = os.path.abspath('../../src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "    print(f\"Added '{src_path}' to the Python path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b3c46a",
   "metadata": {},
   "source": [
    "## 2. The Problem: Unbounded Queues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99def9a",
   "metadata": {},
   "source": [
    "In a typical dataflow, a producer sends messages to a consumer through a queue. If the producer is faster than the consumer, the queue will grow indefinitely, eventually leading to memory exhaustion and system failure. This is known as the \"unbounded queue\" problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c9c825",
   "metadata": {},
   "source": [
    "## 3. Meridian Runtime's Solution: Bounded Edges and Backpressure Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e6cc0e",
   "metadata": {},
   "source": [
    "Meridian Runtime solves this problem by using **bounded edges** (queues with a fixed capacity) and **backpressure policies**. When an edge is full, the runtime applies a backpressure policy to prevent the queue from growing further. Meridian Runtime provides four backpressure policies:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52038c35",
   "metadata": {},
   "source": [
    "* **Block**: The producer is blocked until space becomes available in the queue. This is the default policy.\n",
    "* **Drop**: The new message is dropped.\n",
    "* **Latest**: The oldest message in the queue is dropped to make space for the new message.\n",
    "* **Coalesce**: The new message is merged with an existing message in the queue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e213db",
   "metadata": {},
   "source": [
    "## 4. Demonstrating the Backpressure Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e0be15",
   "metadata": {},
   "source": [
    "Let's see how these policies work in practice. We'll use a simple graph with a fast producer and a slow consumer to simulate a load spike."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5728c1ca",
   "metadata": {},
   "source": [
    "### 4.1. The Base Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33803c2",
   "metadata": {},
   "source": [
    "First, let's define the producer and consumer nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f795e02",
   "metadata": {
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from meridian.core import Node, Message\n",
    "\n",
    "from meridian.core import MessageType, Port, PortDirection, PortSpec\n",
    "\n",
    "class FastProducer(Node):\n",
    "    def __init__(self, n=20):  # Reduced for better demo\n",
    "        super().__init__(\n",
    "            name=\"producer\",\n",
    "            inputs=[],\n",
    "            outputs=[Port(\"out\", PortDirection.OUTPUT, spec=PortSpec(\"out\", int))],\n",
    "        )\n",
    "        self._n = n\n",
    "        self._i = 0\n",
    "        self.produced_count = 0\n",
    "        self.blocked_count = 0\n",
    "\n",
    "    def on_start(self):\n",
    "        self._i = 0\n",
    "        self.produced_count = 0\n",
    "        self.blocked_count = 0\n",
    "\n",
    "    def _handle_tick(self):\n",
    "        # Try to emit multiple messages per tick to trigger backpressure\n",
    "        for _ in range(3):  # Attempt 3 messages per tick\n",
    "            if self._i < self._n:\n",
    "                try:\n",
    "                    msg = Message(type=MessageType.DATA, payload=self._i)\n",
    "                    self.emit(\"out\", msg)\n",
    "                    print(f\"âœ… Produced message {self._i}\")\n",
    "                    self._i += 1\n",
    "                    self.produced_count += 1\n",
    "                except RuntimeError as e:\n",
    "                    if \"Backpressure\" in str(e):\n",
    "                        print(f\"ðŸš« Blocked on message {self._i}\")\n",
    "                        self.blocked_count += 1\n",
    "                        break  # Stop trying more messages this tick\n",
    "                    else:\n",
    "                        raise  # Re-raise non-backpressure errors\n",
    "\n",
    "class SlowConsumer(Node):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"consumer\",\n",
    "            inputs=[Port(\"in\", PortDirection.INPUT, spec=PortSpec(\"in\", int))],\n",
    "            outputs=[],\n",
    "        )\n",
    "        self.consumed_count = 0\n",
    "\n",
    "    def _handle_message(self, port, msg):\n",
    "        print(f\"ðŸ“¥ Consuming message: {msg.payload}\")\n",
    "        time.sleep(0.2)  # Reduced sleep for better demo timing\n",
    "        self.consumed_count += 1\n",
    "\n",
    "    def reset_counts(self):\n",
    "        self.consumed_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8597c8a6",
   "metadata": {},
   "source": [
    "### 4.2. The \"Block\" Policy (Default)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a18c14",
   "metadata": {},
   "source": [
    "The \"Block\" policy is the default policy. When the edge is full, the producer is blocked until the consumer has processed a message and freed up space in the queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3aab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meridian.core import Subgraph, Scheduler, SchedulerConfig\n",
    "\n",
    "# Create a subgraph\n",
    "graph = Subgraph(name=\"block_policy_graph\")\n",
    "\n",
    "# Add the producer and consumer nodes\n",
    "graph.add_node(FastProducer(n=20))\n",
    "graph.add_node(SlowConsumer())\n",
    "\n",
    "# Connect the producer and consumer with a small capacity and Block policy\n",
    "from meridian.core.policies import Block\n",
    "graph.connect((\"producer\", \"out\"), (\"consumer\", \"in\"), capacity=2, policy=Block())\n",
    "\n",
    "# Create a scheduler and register the subgraph\n",
    "scheduler = Scheduler(SchedulerConfig(tick_interval_ms=50, shutdown_timeout_s=5.0))\n",
    "scheduler.register(graph)\n",
    "\n",
    "# Run the scheduler\n",
    "print(\"ðŸš€ Running Block Policy Demo...\")\n",
    "scheduler.run()\n",
    "\n",
    "print(f\"\\n--- Block Policy Results ---\")\n",
    "print(f\"Messages produced: {graph.nodes['producer'].produced_count}\")\n",
    "print(f\"Messages consumed: {graph.nodes['consumer'].consumed_count}\")\n",
    "print(f\"Messages blocked: {graph.nodes['producer'].blocked_count}\")\n",
    "print(f\"----------------------------\\n\")\n",
    "\n",
    "# Reset consumer for next policy\n",
    "graph.nodes['consumer'].reset_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eaeaa9",
   "metadata": {},
   "source": [
    "### 4.3. The \"Drop\" Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0fa1f1",
   "metadata": {},
   "source": [
    "The \"Drop\" policy simply drops the new message when the edge is full."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eca29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meridian.core import Subgraph, Scheduler\n",
    "from meridian.core.policies import drop\n",
    "\n",
    "# Create a subgraph\n",
    "graph = Subgraph(name=\"drop_policy_graph\")\n",
    "\n",
    "# Add the producer and consumer nodes\n",
    "graph.add_node(FastProducer(n=20))\n",
    "graph.add_node(SlowConsumer())\n",
    "\n",
    "# Connect the producer and consumer with the \"Drop\" policy\n",
    "graph.connect((\"producer\", \"out\"), (\"consumer\", \"in\"), capacity=2, policy=drop())\n",
    "\n",
    "# Create a scheduler and register the subgraph\n",
    "scheduler = Scheduler(SchedulerConfig(tick_interval_ms=50, shutdown_timeout_s=5.0))\n",
    "scheduler.register(graph)\n",
    "\n",
    "# Run the scheduler\n",
    "print(\"ðŸš€ Running Drop Policy Demo...\")\n",
    "scheduler.run()\n",
    "\n",
    "print(f\"\\n--- Drop Policy Results ---\")\n",
    "print(f\"Messages produced: {graph.nodes['producer'].produced_count}\")\n",
    "print(f\"Messages consumed: {graph.nodes['consumer'].consumed_count}\")\n",
    "print(f\"Messages dropped: {graph.nodes['producer'].produced_count - graph.nodes['consumer'].consumed_count}\")\n",
    "print(f\"----------------------------\\n\")\n",
    "\n",
    "# Reset consumer for next policy\n",
    "graph.nodes['consumer'].reset_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a8c84e",
   "metadata": {},
   "source": [
    "### 4.4. The \"Latest\" Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f99606",
   "metadata": {},
   "source": [
    "The \"Latest\" policy drops the oldest message in the queue to make space for the new message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d4479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meridian.core import Subgraph, Scheduler\n",
    "from meridian.core.policies import latest\n",
    "\n",
    "# Create a subgraph\n",
    "graph = Subgraph(name=\"latest_policy_graph\")\n",
    "\n",
    "# Add the producer and consumer nodes\n",
    "graph.add_node(FastProducer(n=20))\n",
    "graph.add_node(SlowConsumer())\n",
    "\n",
    "# Connect the producer and consumer with the \"Latest\" policy\n",
    "graph.connect((\"producer\", \"out\"), (\"consumer\", \"in\"), capacity=2, policy=latest())\n",
    "\n",
    "# Create a scheduler and register the subgraph\n",
    "scheduler = Scheduler(SchedulerConfig(tick_interval_ms=50, shutdown_timeout_s=5.0))\n",
    "scheduler.register(graph)\n",
    "\n",
    "# Run the scheduler\n",
    "print(\"ðŸš€ Running Latest Policy Demo...\")\n",
    "scheduler.run()\n",
    "\n",
    "print(f\"\\n--- Latest Policy Results ---\")\n",
    "print(f\"Messages produced: {graph.nodes['producer'].produced_count}\")\n",
    "print(f\"Messages consumed: {graph.nodes['consumer'].consumed_count}\")\n",
    "print(f\"Messages replaced: {graph.nodes['producer'].produced_count - graph.nodes['consumer'].consumed_count}\")\n",
    "print(f\"----------------------------\\n\")\n",
    "\n",
    "# Reset consumer for next policy\n",
    "graph.nodes['consumer'].reset_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773a23aa",
   "metadata": {},
   "source": [
    "### 4.5. The \"Coalesce\" Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84afa515",
   "metadata": {},
   "source": [
    "The \"Coalesce\" policy merges the new message with an existing message in the queue using a user-defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f954908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meridian.core import Subgraph, Scheduler\n",
    "from meridian.core.policies import coalesce\n",
    "\n",
    "def merge_messages(old_msg, new_msg):\n",
    "    \"\"\"Merge two messages by combining their payloads.\"\"\"\n",
    "    old_payload = old_msg.payload if hasattr(old_msg, 'payload') else str(old_msg)\n",
    "    new_payload = new_msg.payload if hasattr(new_msg, 'payload') else str(new_msg)\n",
    "    \n",
    "    # Create a new Message with combined payload\n",
    "    return Message(\n",
    "        type=MessageType.DATA,\n",
    "        payload=f\"{old_payload}+{new_payload}\"\n",
    "    )\n",
    "\n",
    "# Create a subgraph\n",
    "graph = Subgraph(name=\"coalesce_policy_graph\")\n",
    "\n",
    "# Add the producer and consumer nodes\n",
    "graph.add_node(FastProducer(n=20))\n",
    "graph.add_node(SlowConsumer())\n",
    "\n",
    "# Connect the producer and consumer with the \"Coalesce\" policy\n",
    "graph.connect((\"producer\", \"out\"), (\"consumer\", \"in\"), capacity=2, policy=coalesce(merge_messages))\n",
    "\n",
    "# Create a scheduler and register the subgraph\n",
    "scheduler = Scheduler(SchedulerConfig(tick_interval_ms=50, shutdown_timeout_s=5.0))\n",
    "scheduler.register(graph)\n",
    "\n",
    "# Run the scheduler\n",
    "print(\"ðŸš€ Running Coalesce Policy Demo...\")\n",
    "scheduler.run()\n",
    "\n",
    "print(f\"\\n--- Coalesce Policy Results ---\")\n",
    "print(f\"Messages produced: {graph.nodes['producer'].produced_count}\")\n",
    "print(f\"Messages consumed: {graph.nodes['consumer'].consumed_count}\")\n",
    "print(f\"Messages coalesced: {graph.nodes['producer'].produced_count - graph.nodes['consumer'].consumed_count}\")\n",
    "print(f\"----------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd29492",
   "metadata": {},
   "source": [
    "## 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc032e5",
   "metadata": {},
   "source": [
    "This notebook has demonstrated the different backpressure policies available in Meridian Runtime. By choosing the right policy for your use case, you can build robust and resilient dataflows that can handle load spikes and prevent system failures."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
