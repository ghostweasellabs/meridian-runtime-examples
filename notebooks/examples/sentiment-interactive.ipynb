{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d75a871",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd2995bd",
   "metadata": {},
   "source": [
    "---\n",
    "jupyter:\n",
    "  jupytext:\n",
    "    text_representation:\n",
    "      extension: .py\n",
    "      format_name: light\n",
    "      format_version: '1.5'\n",
    "      jupytext_version: 1.17.2\n",
    "  kernelspec:\n",
    "    display_name: Python 3\n",
    "    name: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bf0bf0",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Pipeline (Interactive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730f1321",
   "metadata": {},
   "source": [
    "This notebook demonstrates a real-time sentiment analysis pipeline built with Meridian Runtime. It showcases:\n",
    "- Ingesting streaming text data.\n",
    "- Tokenizing text.\n",
    "- Computing a naive sentiment score.\n",
    "- Using control-plane messages to alter node behavior.\n",
    "- Observing the pipeline's output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011bf5ae",
   "metadata": {},
   "source": [
    "## 1. Setup: Add Project to Python Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7fb9c3",
   "metadata": {},
   "source": [
    "This cell adds the project's `src` directory to the Python path. This is necessary for the notebook to find and import the `meridian` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeeaad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's 'src' directory to the Python path\n",
    "# This is necessary for the notebook to find the 'meridian' module\n",
    "# We assume the notebook is run from the 'notebooks/examples' directory.\n",
    "src_path = os.path.abspath('../../src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "    print(f\"Added '{src_path}' to the Python path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30edcef7",
   "metadata": {},
   "source": [
    "## 2. Domain Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66bf34a",
   "metadata": {},
   "source": [
    "These helper functions are used for tokenization and naive sentiment calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a01330",
   "metadata": {
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import threading\n",
    "import time\n",
    "from typing import Iterable, List, Tuple, Any\n",
    "\n",
    "POSITIVE_WORDS = {\"good\", \"great\", \"awesome\", \"excellent\", \"love\", \"like\", \"win\", \"nice\"}\n",
    "NEGATIVE_WORDS = {\"bad\", \"terrible\", \"awful\", \"hate\", \"dislike\", \"lose\", \"worse\", \"nope\"}\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    return [w.strip(\".,!?;:\").lower() for w in text.split() if w.strip()]\n",
    "\n",
    "def naive_sentiment(words: Iterable[str]) -> float:\n",
    "    p = sum(1 for w in words if w in POSITIVE_WORDS)\n",
    "    n = sum(1 for w in words if w in NEGATIVE_WORDS)\n",
    "    if p == n == 0:\n",
    "        return 0.0\n",
    "    return (p - n) / max(1, (p + n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45778eb2",
   "metadata": {},
   "source": [
    "## 3. Pipeline Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d82682",
   "metadata": {},
   "source": [
    "Here are the definitions for the nodes that make up our sentiment analysis pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb294bf8",
   "metadata": {},
   "source": [
    "*   **IngestNode**: Simulates a streaming data source.\n",
    "*   **TokenizeNode**: Breaks text into individual words.\n",
    "*   **SentimentNode**: Calculates a sentiment score.\n",
    "*   **SinkNode**: Collects and displays results.\n",
    "*   **ControlNode**: Sends control messages to other nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657ecb51",
   "metadata": {
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from meridian.core import (\n",
    "    Edge,\n",
    "    Message,\n",
    "    MessageType,\n",
    "    Node,\n",
    "    Port,\n",
    "    PortDirection,\n",
    "    PortSpec,\n",
    "    Scheduler,\n",
    "    SchedulerConfig,\n",
    "    Subgraph,\n",
    ")\n",
    "from meridian.core.policies import Block, Latest\n",
    "from meridian.observability.config import (\n",
    "    ObservabilityConfig,\n",
    "    configure_observability,\n",
    ")\n",
    "from meridian.observability.logging import get_logger, with_context\n",
    "\n",
    "\n",
    "class IngestNode(Node):\n",
    "    \"\"\"\n",
    "    Emits DATA messages containing raw text.\n",
    "    A separate thread feeds samples into an internal buffer to simulate streaming.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name: str = \"ingest\", rate_hz: float = 10.0) -> None:\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            inputs=[],\n",
    "            outputs=[Port(\"text\", PortDirection.OUTPUT, spec=PortSpec(\"text\", str))],\n",
    "        )\n",
    "        self._buf: list[str] = []\n",
    "        self._stop = False\n",
    "        self._rate_hz = rate_hz\n",
    "        self._producer_t: threading.Thread | None = None\n",
    "        self._samples = [\n",
    "            \"I love this product, it is awesome!\",\n",
    "            \"This is bad, I dislike the changes\",\n",
    "            \"What a great day to win and feel excellent\",\n",
    "            \"Awful behavior and terrible support\",\n",
    "            \"Nice work, really like the new UI\",\n",
    "            \"Nope, this is worse than before\",\n",
    "        ]\n",
    "\n",
    "    def on_start(self) -> None:\n",
    "        super().on_start()\n",
    "        self._stop = False\n",
    "        self._producer_t = threading.Thread(target=self._feeder, daemon=True)\n",
    "        self._producer_t.start()\n",
    "\n",
    "    def on_stop(self) -> None:\n",
    "        self._stop = True\n",
    "        if self._producer_t and self._producer_t.is_alive():\n",
    "            self._producer_t.join(timeout=1.0)\n",
    "        super().on_stop()\n",
    "\n",
    "    def _feeder(self) -> None:\n",
    "        rng = random.Random(42)\n",
    "        while not self._stop:\n",
    "            s = rng.choice(self._samples)\n",
    "            self._buf.append(s)\n",
    "            time.sleep(1.0 / max(1e-6, self._rate_hz))\n",
    "\n",
    "    def _handle_tick(self) -> None:\n",
    "        # Emit one item per tick if available\n",
    "        if self._buf:\n",
    "            s = self._buf.pop(0)\n",
    "            self.emit(\"text\", Message(MessageType.DATA, s))\n",
    "\n",
    "\n",
    "class TokenizeNode(Node):\n",
    "    \"\"\"Converts raw text to a list of tokens.\"\"\"\n",
    "\n",
    "    def __init__(self, name: str = \"tokenize\") -> None:\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            inputs=[Port(\"in\", PortDirection.INPUT, spec=PortSpec(\"in\", str))],\n",
    "            outputs=[Port(\"out\", PortDirection.OUTPUT, spec=PortSpec(\"out\", list))],\n",
    "        )\n",
    "\n",
    "    def _handle_message(self, port: str, msg: Message) -> None:\n",
    "        tokens = tokenize(str(msg.payload))\n",
    "        self.emit(\"out\", Message(MessageType.DATA, tokens))\n",
    "\n",
    "\n",
    "class SentimentNode(Node):\n",
    "    \"\"\"Computes a naive sentiment score from tokens. Supports CONTROL to change mode.\"\"\"\n",
    "\n",
    "    def __init__(self, name: str = \"sentiment\") -> None:\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            inputs=[\n",
    "                Port(\"in\", PortDirection.INPUT, spec=PortSpec(\"in\", list)),\n",
    "                Port(\"ctl\", PortDirection.INPUT, spec=PortSpec(\"ctl\", str)),\n",
    "            ],\n",
    "            outputs=[\n",
    "                Port(\"scored\", PortDirection.OUTPUT, spec=PortSpec(\"scored\", tuple)),\n",
    "            ],\n",
    "        )\n",
    "        # modes: \"avg\" or \"binary\"\n",
    "        self._mode = \"avg\"\n",
    "\n",
    "    def _handle_message(self, port: str, msg: Message) -> None:\n",
    "        if port == \"ctl\":\n",
    "            # CONTROL messages can switch mode\n",
    "            cmd = str(msg.payload).strip().lower()\n",
    "            if cmd in {\"avg\", \"binary\"}:\n",
    "                self._mode = cmd\n",
    "            return\n",
    "\n",
    "        words = msg.payload\n",
    "        if not isinstance(words, list):\n",
    "            return\n",
    "\n",
    "        score = naive_sentiment(words)\n",
    "        if self._mode == \"binary\":\n",
    "            score = 1.0 if score > 0 else (-1.0 if score < 0 else 0.0)\n",
    "        self.emit(\"scored\", Message(MessageType.DATA, (words, score)))\n",
    "\n",
    "\n",
    "class SinkNode(Node):\n",
    "    \"\"\"Renders the latest N results; CONTROL can flush or toggle verbosity.\"\"\"\n",
    "\n",
    "    def __init__(self, name: str = \"sink\", keep: int = 10, verbose: bool = True) -> None:\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            inputs=[\n",
    "                Port(\"in\", PortDirection.INPUT, spec=PortSpec(\"in\", tuple)),\n",
    "                Port(\"ctl\", PortDirection.INPUT, spec=PortSpec(\"ctl\", str)),\n",
    "            ],\n",
    "            outputs=[],\n",
    "        )\n",
    "        self._keep = keep\n",
    "        self._verbose = verbose\n",
    "        self._buffer: list[Tuple[List[str], float]] = []\n",
    "\n",
    "    def _handle_message(self, port: str, msg: Message) -> None:\n",
    "        logger = get_logger()\n",
    "        if port == \"ctl\":\n",
    "            cmd = str(msg.payload).strip().lower()\n",
    "            if cmd == \"flush\":\n",
    "                with with_context(node=self.name):\n",
    "                    logger.info(\"sink.flush\", \"Flushing buffer\")\n",
    "                self._buffer.clear()\n",
    "            elif cmd == \"quiet\":\n",
    "                self._verbose = False\n",
    "            elif cmd == \"verbose\":\n",
    "                self._verbose = True\n",
    "            return\n",
    "\n",
    "        words, score = msg.payload\n",
    "        self._buffer.append((words, score))\n",
    "        if len(self._buffer) > self._keep:\n",
    "            self._buffer.pop(0)\n",
    "\n",
    "        if self._verbose:\n",
    "            text = \" \".join(words)\n",
    "            with with_context(node=self.name):\n",
    "                logger.info(\n",
    "                    \"sink.item\",\n",
    "                    f\"[{score:+.2f}] {text}\",\n",
    "                    score=score,\n",
    "                    len=len(words),\n",
    "                )\n",
    "\n",
    "    def _handle_tick(self) -> None:\n",
    "        # periodic summary\n",
    "        if not self._buffer:\n",
    "            return\n",
    "        avg = sum(s for _, s in self._buffer) / len(self._buffer)\n",
    "        logger = get_logger()\n",
    "        with with_context(node=self.name):\n",
    "            logger.info(\"sink.summary\", f\"buffer={len(self._buffer)} avg={avg:+.2f}\", avg=avg)\n",
    "\n",
    "\n",
    "class ControlNode(Node):\n",
    "    \"\"\"Emits CONTROL messages periodically to demonstrate preemption.\"\"\"\n",
    "\n",
    "    def __init__(self, name: str = \"control\", period_s: float = 5.0) -> None:\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            inputs=[],\n",
    "            outputs=[Port(\"ctl\", PortDirection.OUTPUT, spec=PortSpec(\"ctl\", str))],\n",
    "        )\n",
    "        self._period_s = period_s\n",
    "        self._last = 0.0\n",
    "        self._ops = [\"avg\", \"binary\", \"flush\", \"quiet\", \"verbose\"]\n",
    "        self._i = 0\n",
    "\n",
    "    def _handle_tick(self) -> None:\n",
    "        now = time.monotonic()\n",
    "        if now - self._last >= self._period_s:\n",
    "            self._last = now\n",
    "            cmd = self._ops[self._i % len(self._ops)]\n",
    "            self._i += 1\n",
    "            self.emit(\"ctl\", Message(MessageType.CONTROL, cmd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b48fed",
   "metadata": {},
   "source": [
    "## 4. Interactive Controls and Running the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f12a0b0",
   "metadata": {},
   "source": [
    "Use the widgets below to configure and run the sentiment analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e7c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Configure observability for the notebook\n",
    "configure_observability(\n",
    "    ObservabilityConfig(\n",
    "        log_level=\"INFO\",\n",
    "        log_json=False,  # Human-readable logs for notebook\n",
    "        metrics_enabled=False,\n",
    "        tracing_enabled=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create widgets for pipeline parameters\n",
    "rate_hz_slider = widgets.FloatSlider(value=8.0, min=1.0, max=20.0, step=1.0, description='Ingest Rate (Hz):')\n",
    "control_period_slider = widgets.FloatSlider(value=4.0, min=1.0, max=10.0, step=1.0, description='Control Period (s):')\n",
    "keep_slider = widgets.IntSlider(value=10, min=1, max=50, step=1, description='Sink Buffer Size:')\n",
    "quiet_checkbox = widgets.Checkbox(value=False, description='Quiet Sink (summary only)')\n",
    "tick_ms_slider = widgets.IntSlider(value=25, min=10, max=100, step=5, description='Scheduler Tick (ms):')\n",
    "max_batch_slider = widgets.IntSlider(value=8, min=1, max=32, step=1, description='Max Batch Size:')\n",
    "timeout_s_slider = widgets.FloatSlider(value=6.0, min=1.0, max=20.0, step=1.0, description='Shutdown Timeout (s):')\n",
    "cap_text_slider = widgets.IntSlider(value=64, min=16, max=256, step=16, description='Capacity: Text Edge:')\n",
    "cap_tokens_slider = widgets.IntSlider(value=64, min=16, max=256, step=16, description='Capacity: Tokens Edge:')\n",
    "cap_scored_slider = widgets.IntSlider(value=128, min=32, max=512, step=32, description='Capacity: Scored Edge:')\n",
    "cap_control_slider = widgets.IntSlider(value=8, min=1, max=32, step=1, description='Capacity: Control Edges:')\n",
    "\n",
    "run_button = widgets.Button(description='Run Sentiment Pipeline')\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def run_sentiment_pipeline(b):\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        print(\"=== Starting Sentiment Pipeline Demo ===\")\n",
    "\n",
    "        ingest = IngestNode(rate_hz=rate_hz_slider.value)\n",
    "        tok = TokenizeNode()\n",
    "        sent = SentimentNode()\n",
    "        ctrl = ControlNode(period_s=control_period_slider.value)\n",
    "        sink = SinkNode(keep=keep_slider.value, verbose=not quiet_checkbox.value)\n",
    "\n",
    "        g = Subgraph.from_nodes(\"sentiment_pipeline\", [ingest, tok, sent, ctrl, sink])\n",
    "\n",
    "        # Wiring:\n",
    "        # ingest(text) -> tokenize(in) -> sentiment(in) -> sink(in)\n",
    "        # control(ctl) -> sentiment(ctl) [CONTROL priority], and to sink(ctl)\n",
    "        g.connect((ingest.name, \"text\"), (tok.name, \"in\"), capacity=cap_text_slider.value)\n",
    "        g.connect((tok.name, \"out\"), (sent.name, \"in\"), capacity=cap_tokens_slider.value)\n",
    "        g.connect((sent.name, \"scored\"), (sink.name, \"in\"), capacity=cap_scored_slider.value)\n",
    "\n",
    "        # Control lines: keep capacity small; impose Block for CONTROL in scheduler\n",
    "        g.connect((ctrl.name, \"ctl\"), (sent.name, \"ctl\"), capacity=cap_control_slider.value)\n",
    "        g.connect((ctrl.name, \"ctl\"), (sink.name, \"ctl\"), capacity=cap_control_slider.value)\n",
    "\n",
    "        sched = Scheduler(\n",
    "            SchedulerConfig(\n",
    "                tick_interval_ms=tick_ms_slider.value,\n",
    "                fairness_ratio=(4, 2, 1),\n",
    "                max_batch_per_node=max_batch_slider.value,\n",
    "                idle_sleep_ms=1,\n",
    "                shutdown_timeout_s=timeout_s_slider.value,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        sched.register(g)\n",
    "\n",
    "        logger = get_logger()\n",
    "        with with_context(node=\"driver\"):\n",
    "            logger.info(\"demo.start\", \"Starting sentiment pipeline demo\")\n",
    "\n",
    "        # Run in a separate thread to keep notebook interactive\n",
    "        pipeline_thread = threading.Thread(target=sched.run)\n",
    "        pipeline_thread.start()\n",
    "        pipeline_thread.join() # Wait for pipeline to complete\n",
    "\n",
    "        with with_context(node=\"driver\"):\n",
    "            logger.info(\"demo.stop\", \"Sentiment pipeline stopped\")\n",
    "\n",
    "        print(\"=== Sentiment Pipeline Demo Finished ===\")\n",
    "\n",
    "run_button.on_click(run_sentiment_pipeline)\n",
    "\n",
    "display(\n",
    "    rate_hz_slider,\n",
    "    control_period_slider,\n",
    "    keep_slider,\n",
    "    quiet_checkbox,\n",
    "    tick_ms_slider,\n",
    "    max_batch_slider,\n",
    "    timeout_s_slider,\n",
    "    cap_text_slider,\n",
    "    cap_tokens_slider,\n",
    "    cap_scored_slider,\n",
    "    cap_control_slider,\n",
    "    run_button,\n",
    "    output_area\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
