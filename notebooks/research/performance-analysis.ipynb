{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32dac7e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a8ae870",
   "metadata": {},
   "source": [
    "---\n",
    "jupyter:\n",
    "  jupytext:\n",
    "    text_representation:\n",
    "      extension: .py\n",
    "      format_name: light\n",
    "      format_version: '1.5'\n",
    "      jupytext_version: 1.17.2\n",
    "  kernelspec:\n",
    "    display_name: Python 3\n",
    "    name: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a49fff2",
   "metadata": {},
   "source": [
    "# Performance Analysis of Meridian Runtime Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6d4dc",
   "metadata": {},
   "source": [
    "This notebook provides an interactive way to benchmark the Meridian Runtime scheduler's performance. It allows you to configure various parameters like the number of producers and consumers, edge capacity, and scheduler tick interval, then visualize the impact on scheduler loop latency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01bfb16",
   "metadata": {},
   "source": [
    "## 1. Setup: Add Project to Python Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e289efc",
   "metadata": {},
   "source": [
    "This cell adds the project's `src` directory to the Python path. This is necessary for the notebook to find and import the `meridian` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0b33e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's 'src' directory to the Python path\n",
    "# This is necessary for the notebook to find the 'meridian' module\n",
    "# We assume the notebook is run from the 'notebooks/research' directory.\n",
    "src_path = os.path.abspath('../../src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "    print(f\"Added '{src_path}' to the Python path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e6dfc2",
   "metadata": {},
   "source": [
    "## 2. Imports and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13901af",
   "metadata": {},
   "source": [
    "We'll import necessary modules and define a configuration class to hold our benchmark parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e8de4a",
   "metadata": {
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import random\n",
    "import threading\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "from meridian.core import Node, Scheduler, SchedulerConfig, Subgraph, Message, MessageType\n",
    "from meridian.core.ports import Port, PortDirection, PortSpec\n",
    "from meridian.observability.metrics import (\n",
    "    PrometheusMetrics,\n",
    "    configure_metrics,\n",
    "    get_metrics,\n",
    ")\n",
    "\n",
    "@dataclass\n",
    "class BenchSchedConfig:\n",
    "    seconds: float = 5.0\n",
    "    producers: int = 2\n",
    "    consumers: int = 2\n",
    "    capacity: int = 1024\n",
    "    tick_interval_ms: int = 1\n",
    "    idle_sleep_ms: int = 0\n",
    "    shutdown_timeout_s: float = 2.0\n",
    "    fairness_ratio: Tuple[int, int, int] = (4, 2, 1)\n",
    "    max_batch_per_node: int = 128\n",
    "    seed: int = 8675309"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9170697c",
   "metadata": {},
   "source": [
    "## 3. Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd031e1",
   "metadata": {},
   "source": [
    "These functions are adapted from `bench_scheduler.py` to work within the notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fe6be4",
   "metadata": {
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def _percentile_from_histogram_cumulative(\n",
    "    buckets: Dict[float, int], total: int, pct: float\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Estimate percentile from a cumulative histogram mapping (upper_bound -> cumulative count).\n",
    "    Includes +Inf as float('inf').\n",
    "    \"\"\"\n",
    "    if total <= 0 or not buckets:\n",
    "        return float(\"nan\")\n",
    "    if pct <= 0:\n",
    "        # First non-zero bucket upper bound\n",
    "        for ub in sorted(buckets.keys(), key=lambda x: float(x)):\n",
    "            if buckets[ub] > 0:\n",
    "                return float(ub)\n",
    "        return float(\"nan\")\n",
    "    if pct >= 100:\n",
    "        return float(\"inf\")\n",
    "    target = math.ceil((pct / 100.0) * total)\n",
    "    for ub in sorted(buckets.keys(), key=lambda x: float(x)):\n",
    "        if buckets[ub] >= target:\n",
    "            return float(ub)\n",
    "    # Fallback if not found\n",
    "    return float(\"inf\")\n",
    "\n",
    "\n",
    "def _maybe_enable_prom_metrics() -> None:\n",
    "    \"\"\"\n",
    "    Ensure PrometheusMetrics is enabled so the scheduler loop histogram is populated.\n",
    "    \"\"\"\n",
    "    metrics = get_metrics()\n",
    "    if not isinstance(metrics, PrometheusMetrics):\n",
    "        configure_metrics(PrometheusMetrics())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d948aa06",
   "metadata": {},
   "source": [
    "## 4. Workload Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60403a31",
   "metadata": {},
   "source": [
    "These are the `Producer` and `Consumer` nodes used to generate and process messages, simulating a workload for the scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de3a8a0",
   "metadata": {
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class Producer(Node):\n",
    "    \"\"\"\n",
    "    Producer emits increasing integers on each tick to generate message load.\n",
    "    Emits Message(DATA, payload) via a declared output port, per runtime contract.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name: str, out_port: Port, burst_max: int = 8) -> None:\n",
    "        super().__init__(name)\n",
    "        # Ensure Node has a matching output port name so Node.emit() can resolve it\n",
    "        self.outputs = [out_port]\n",
    "        self._out = out_port\n",
    "        self._burst_max = max(1, burst_max)\n",
    "        self._seq = 0\n",
    "\n",
    "    def on_start(self) -> None:\n",
    "        self._seq = 0\n",
    "\n",
    "    def _handle_tick(self) -> None:\n",
    "        # Emit a burst of messages to keep the scheduler busy\n",
    "        burst = random.randint(1, self._burst_max)\n",
    "        for _ in range(burst):\n",
    "            msg = Message(MessageType.DATA, self._seq)\n",
    "            self.emit(self._out.name, msg)\n",
    "            self._seq += 1\n",
    "\n",
    "\n",
    "class Consumer(Node):\n",
    "    \"\"\"\n",
    "    Consumer counts messages; work is intentionally light to focus on scheduler loop behavior.\n",
    "    Declares input port so scheduler can route messages by port name.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name: str, in_port: Port, batch_max: int = 32) -> None:\n",
    "        super().__init__(name)\n",
    "        # Ensure Node declares the input port for routing\n",
    "        self.inputs = [in_port]\n",
    "        self._in = in_port\n",
    "        self._batch_max = max(1, batch_max)\n",
    "        self._processed = 0\n",
    "\n",
    "    def on_start(self) -> None:\n",
    "        self._processed = 0\n",
    "\n",
    "    def on_message(self, port: Port, msg: Any) -> None:\n",
    "        self._processed += 1\n",
    "\n",
    "    def on_tick(self) -> None:\n",
    "        # Tick present to participate in fairness, but primary work is message-driven\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def processed(self) -> int:\n",
    "        return self._processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4bc0ec",
   "metadata": {},
   "source": [
    "## 5. Topology Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef5e72a",
   "metadata": {},
   "source": [
    "This function builds the graph of producers and consumers based on the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c718350",
   "metadata": {
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def _mk_ports(n: int = 4) -> Tuple[List[Port], List[Port]]:\n",
    "    outs: List[Port] = []\n",
    "    ins: List[Port] = []\n",
    "    for i in range(n):\n",
    "        outs.append(Port(f\"o{i}\", PortDirection.OUTPUT, PortSpec(f\"o{i}\", int)))\n",
    "        ins.append(Port(f\"i{i}\", PortDirection.INPUT, PortSpec(f\"i{i}\", int)))\n",
    "    return outs, ins\n",
    "\n",
    "\n",
    "def _mk_subgraph(cfg: BenchSchedConfig) -> Tuple[Subgraph, List[Consumer]]:\n",
    "    outs, ins = _mk_ports(max(cfg.producers, cfg.consumers))\n",
    "    producers: List[Producer] = []\n",
    "    consumers: List[Consumer] = []\n",
    "\n",
    "    for p in range(cfg.producers):\n",
    "        producers.append(Producer(f\"prod{p}\", outs[p % len(outs)], burst_max=8))\n",
    "    for c in range(cfg.consumers):\n",
    "        consumers.append(Consumer(f\"cons{c}\", ins[c % len(ins)], batch_max=32))\n",
    "\n",
    "    # Build subgraph with nodes and explicitly wire producer outputs to consumer inputs\n",
    "    g = Subgraph.from_nodes(\"bench_sched_topology\", [*producers, *consumers])\n",
    "    for p in producers:\n",
    "        for c in consumers:\n",
    "            g.connect((p.name, p._out.name), (c.name, c._in.name), capacity=cfg.capacity)\n",
    "    return g, consumers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2a7a1e",
   "metadata": {},
   "source": [
    "## 6. Metrics Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc889d05",
   "metadata": {},
   "source": [
    "This function extracts the scheduler loop latency histogram from the metrics system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a636b3c2",
   "metadata": {
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def _get_scheduler_loop_hist() -> Tuple[float, int, Dict[float, int]]:\n",
    "    \"\"\"\n",
    "    Returns (sum, count, buckets) for scheduler_loop_latency_seconds.\n",
    "    \"\"\"\n",
    "    metrics = get_metrics()\n",
    "    if not isinstance(metrics, PrometheusMetrics):\n",
    "        return (0.0, 0, {})\n",
    "    hists = metrics.get_all_histograms()\n",
    "    for key, hist in hists.items():\n",
    "        if key.endswith(\"scheduler_loop_latency_seconds\"):\n",
    "            return (hist.sum, hist.count, hist.buckets)\n",
    "    return (0.0, 0, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466302de",
   "metadata": {},
   "source": [
    "## 7. Benchmark Runner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e929eb93",
   "metadata": {},
   "source": [
    "This function runs the scheduler for a specified duration and collects performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a886a1",
   "metadata": {
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def _run_scheduler(cfg: BenchSchedConfig) -> Dict[str, Any]:\n",
    "    # Deterministic randomness for repeatability\n",
    "    random.seed(cfg.seed)\n",
    "\n",
    "    # Ensure histogram is available\n",
    "    _maybe_enable_prom_metrics()\n",
    "\n",
    "    # Build topology and scheduler\n",
    "    g, consumers = _mk_subgraph(cfg)\n",
    "    s_cfg = SchedulerConfig(\n",
    "        fairness_ratio=cfg.fairness_ratio,\n",
    "        max_batch_per_node=cfg.max_batch_per_node,\n",
    "        idle_sleep_ms=cfg.idle_sleep_ms,\n",
    "        tick_interval_ms=cfg.tick_interval_ms,\n",
    "        shutdown_timeout_s=cfg.shutdown_timeout_s,\n",
    "    )\n",
    "    sched = Scheduler(s_cfg)\n",
    "    sched.register(g)\n",
    "\n",
    "    # Run scheduler in background\n",
    "    t = threading.Thread(target=sched.run, name=\"bench-scheduler\", daemon=True)\n",
    "    t.start()\n",
    "\n",
    "    # Let it run for configured duration\n",
    "    time.sleep(cfg.seconds)\n",
    "\n",
    "    # Request shutdown and wait\n",
    "    sched.shutdown()\n",
    "    t.join(timeout=cfg.shutdown_timeout_s + 5.0)\n",
    "\n",
    "    # Gather metrics\n",
    "    h_sum, h_count, h_buckets = _get_scheduler_loop_hist()\n",
    "    p50 = _percentile_from_histogram_cumulative(h_buckets, h_count, 50.0)\n",
    "    p95 = _percentile_from_histogram_cumulative(h_buckets, h_count, 95.0)\n",
    "    p99 = _percentile_from_histogram_cumulative(h_buckets, h_count, 99.0)\n",
    "\n",
    "    total_processed = sum(c.processed for c in consumers)\n",
    "\n",
    "    return {\n",
    "        \"name\": \"scheduler_loop\",\n",
    "        \"version\": 1,\n",
    "        \"env\": {\n",
    "            \"python\": f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\",\n",
    "            \"platform\": sys.platform,\n",
    "        },\n",
    "        \"config\": {\n",
    "            \"seconds\": cfg.seconds,\n",
    "            \"producers\": cfg.producers,\n",
    "            \"consumers\": cfg.consumers,\n",
    "            \"capacity\": cfg.capacity,\n",
    "            \"tick_interval_ms\": cfg.tick_interval_ms,\n",
    "            \"idle_sleep_ms\": cfg.idle_sleep_ms,\n",
    "            \"shutdown_timeout_s\": cfg.shutdown_timeout_s,\n",
    "            \"fairness_ratio\": list(cfg.fairness_ratio),\n",
    "            \"max_batch_per_node\": cfg.max_batch_per_node,\n",
    "            \"seed\": cfg.seed,\n",
    "        },\n",
    "        \"results\": {\n",
    "            \"scheduler_loop_latency_seconds\": {\n",
    "                \"sum\": h_sum,\n",
    "                \"count\": h_count,\n",
    "                \"p50_estimate_seconds\": p50,\n",
    "                \"p95_estimate_seconds\": p95,\n",
    "                \"p99_estimate_seconds\": p99,\n",
    "                \"buckets\": {str(k): int(v) for k, v in h_buckets.items()},\n",
    "            },\n",
    "            \"total_processed\": int(total_processed),\n",
    "            \"iterations_per_second_estimate\": (\n",
    "                (h_count / cfg.seconds) if (cfg.seconds > 0 and h_count > 0) else 0.0\n",
    "            ),\n",
    "        },\n",
    "        \"summary\": {\n",
    "            \"loop_p95_ms\": (p95 * 1000.0) if not math.isnan(p95) and not math.isinf(p95) else None,\n",
    "            \"loop_p99_ms\": (p99 * 1000.0) if not math.isnan(p99) and not math.isinf(p99) else None,\n",
    "            \"processed\": int(total_processed),\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ac8f6",
   "metadata": {},
   "source": [
    "## 8. Interactive Benchmark Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde05395",
   "metadata": {},
   "source": [
    "Use the widgets below to configure and run the scheduler benchmark. The results will be displayed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc95372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create widgets for benchmark parameters\n",
    "seconds_slider = widgets.FloatSlider(value=5.0, min=1.0, max=30.0, step=1.0, description='Duration (s):')\n",
    "producers_slider = widgets.IntSlider(value=2, min=1, max=10, step=1, description='Producers:')\n",
    "consumers_slider = widgets.IntSlider(value=2, min=1, max=10, step=1, description='Consumers:')\n",
    "capacity_slider = widgets.IntSlider(value=1024, min=16, max=4096, step=16, description='Edge Capacity:')\n",
    "tick_ms_slider = widgets.IntSlider(value=1, min=1, max=100, step=1, description='Tick Interval (ms):')\n",
    "idle_sleep_ms_slider = widgets.IntSlider(value=0, min=0, max=10, step=1, description='Idle Sleep (ms):')\n",
    "shutdown_timeout_s_slider = widgets.FloatSlider(value=2.0, min=1.0, max=10.0, step=1.0, description='Shutdown Timeout (s):')\n",
    "fairness_ratio_text = widgets.Text(value='4,2,1', description='Fairness Ratio (ctl,high,norm):')\n",
    "max_batch_per_node_slider = widgets.IntSlider(value=128, min=1, max=512, step=1, description='Max Batch Per Node:')\n",
    "seed_text = widgets.IntText(value=8675309, description='Random Seed:')\n",
    "\n",
    "run_benchmark_button = widgets.Button(description='Run Benchmark')\n",
    "benchmark_output = widgets.Output()\n",
    "\n",
    "def on_run_benchmark_button_clicked(b):\n",
    "    with benchmark_output:\n",
    "        benchmark_output.clear_output()\n",
    "        print(\"Running benchmark...\")\n",
    "\n",
    "        cfg = BenchSchedConfig(\n",
    "            seconds=seconds_slider.value,\n",
    "            producers=producers_slider.value,\n",
    "            consumers=consumers_slider.value,\n",
    "            capacity=capacity_slider.value,\n",
    "            tick_interval_ms=tick_ms_slider.value,\n",
    "            idle_sleep_ms=idle_sleep_ms_slider.value,\n",
    "            shutdown_timeout_s=shutdown_timeout_s_slider.value,\n",
    "            fairness_ratio=tuple(int(x) for x in fairness_ratio_text.value.split(',')),\n",
    "            max_batch_per_node=max_batch_per_node_slider.value,\n",
    "            seed=seed_text.value,\n",
    "        )\n",
    "\n",
    "        results = _run_scheduler(cfg)\n",
    "        print(json.dumps(results, indent=2))\n",
    "\n",
    "run_benchmark_button.on_click(on_run_benchmark_button_clicked)\n",
    "\n",
    "display(\n",
    "    seconds_slider,\n",
    "    producers_slider,\n",
    "    consumers_slider,\n",
    "    capacity_slider,\n",
    "    tick_ms_slider,\n",
    "    idle_sleep_ms_slider,\n",
    "    shutdown_timeout_s_slider,\n",
    "    fairness_ratio_text,\n",
    "    max_batch_per_node_slider,\n",
    "    seed_text,\n",
    "    run_benchmark_button,\n",
    "    benchmark_output\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
