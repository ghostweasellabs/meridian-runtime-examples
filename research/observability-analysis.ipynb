{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b5531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ff8a1b1",
   "metadata": {},
   "source": [
    "---\n",
    "jupyter:\n",
    "  jupytext:\n",
    "    text_representation:\n",
    "      extension: .py\n",
    "      format_name: light\n",
    "      format_version: '1.5'\n",
    "      jupytext_version: 1.17.2\n",
    "  kernelspec:\n",
    "    display_name: Python 3\n",
    "    name: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741483bd",
   "metadata": {},
   "source": [
    "# Observability Analysis with Meridian Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3fec79",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to capture, filter, and analyze observability data (logs and metrics) from Meridian Runtime. It showcases how to gain insights into the behavior of your dataflows using structured logging and Prometheus-style metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7935efa7",
   "metadata": {},
   "source": [
    "## 1. Setup: Add Project to Python Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0aeff4",
   "metadata": {},
   "source": [
    "This cell adds the project's `src` directory to the Python path. This is necessary for the notebook to find and import the `meridian` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec0fb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's 'src' directory to the Python path\n",
    "# This is necessary for the notebook to find the 'meridian' module\n",
    "# We assume the notebook is run from the 'notebooks/research' directory.\n",
    "src_path = os.path.abspath('../../src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "    print(f\"Added '{src_path}' to the Python path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70fa385",
   "metadata": {},
   "source": [
    "## 2. Imports and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35c99d6",
   "metadata": {},
   "source": [
    "We'll import necessary modules and configure observability to capture logs and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10942267",
   "metadata": {
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import time\n",
    "import threading\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from meridian.core import Node, Message, MessageType, Port, PortDirection, PortSpec, Subgraph, Scheduler, SchedulerConfig\n",
    "from meridian.observability.config import ObservabilityConfig, configure_observability\n",
    "from meridian.observability.logging import get_logger\n",
    "from meridian.observability.metrics import PrometheusMetrics, configure_metrics, get_metrics\n",
    "\n",
    "# Use an in-memory stream to capture logs\n",
    "log_stream = io.StringIO()\n",
    "\n",
    "# Configure observability to capture logs and metrics\n",
    "configure_observability(\n",
    "    ObservabilityConfig(\n",
    "        log_level=\"DEBUG\", # Capture all logs for analysis\n",
    "        log_json=True,     # Emit JSON logs for easy parsing\n",
    "        log_stream=log_stream,\n",
    "        metrics_enabled=True,\n",
    "        metrics_namespace=\"demo_app\",\n",
    "        tracing_enabled=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Ensure PrometheusMetrics is configured for metric collection\n",
    "configure_metrics(PrometheusMetrics())\n",
    "\n",
    "logger = get_logger()\n",
    "metrics = get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a338302",
   "metadata": {},
   "source": [
    "## 3. Graph Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69531de9",
   "metadata": {},
   "source": [
    "We'll define a simple graph with a producer, a processing node, and a consumer to generate observability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d34927",
   "metadata": {
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class DataProducer(Node):\n",
    "    def __init__(self, n=100):\n",
    "        super().__init__(\n",
    "            name=\"producer\",\n",
    "            inputs=[],\n",
    "            outputs=[Port(\"out\", PortDirection.OUTPUT, spec=PortSpec(\"out\", int))],\n",
    "        )\n",
    "        self._n = n\n",
    "        self._i = 0\n",
    "\n",
    "    def _handle_tick(self):\n",
    "        if self._i < self._n:\n",
    "            self.emit(\"out\", Message(type=MessageType.DATA, payload=self._i))\n",
    "            self._i += 1\n",
    "        else:\n",
    "            # Stop the producer when done\n",
    "            self.stop()\n",
    "\n",
    "class DataProcessor(Node):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"processor\",\n",
    "            inputs=[Port(\"in\", PortDirection.INPUT, spec=PortSpec(\"in\", int))],\n",
    "            outputs=[Port(\"out\", PortDirection.OUTPUT, spec=PortSpec(\"out\", int))],\n",
    "        )\n",
    "\n",
    "    def _handle_message(self, port, msg):\n",
    "        # Simulate some processing time\n",
    "        time.sleep(0.005)\n",
    "        self.emit(\"out\", Message(type=MessageType.DATA, payload=msg.payload * 2))\n",
    "\n",
    "class DataConsumer(Node):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"consumer\",\n",
    "            inputs=[Port(\"in\", PortDirection.INPUT, spec=PortSpec(\"in\", int))],\n",
    "            outputs=[],\n",
    "        )\n",
    "        self.received_messages = []\n",
    "\n",
    "    def _handle_message(self, port, msg):\n",
    "        self.received_messages.append(msg.payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf392f36",
   "metadata": {},
   "source": [
    "## 4. Running the Simulation and Collecting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df679492",
   "metadata": {},
   "source": [
    "We'll run the graph and collect all logs and metrics generated during its execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ff7b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation_and_collect_data(num_messages=100, capacity=10):\n",
    "    # Clear previous logs\n",
    "    log_stream.seek(0)\n",
    "    log_stream.truncate(0)\n",
    "\n",
    "    producer = DataProducer(n=num_messages)\n",
    "    processor = DataProcessor()\n",
    "    consumer = DataConsumer()\n",
    "\n",
    "    sg = Subgraph.from_nodes(\"observability_demo\", [producer, processor, consumer])\n",
    "    sg.connect((\"producer\", \"out\"), (\"processor\", \"in\"), capacity=capacity)\n",
    "    sg.connect((\"processor\", \"out\"), (\"consumer\", \"in\"), capacity=capacity)\n",
    "\n",
    "    scheduler = Scheduler(SchedulerConfig(tick_interval_ms=1, shutdown_timeout_s=10.0))\n",
    "    scheduler.register(sg)\n",
    "\n",
    "    print(\"ðŸš€ Running simulation and collecting data...\")\n",
    "    scheduler.run()\n",
    "    print(\"Simulation finished.\")\n",
    "\n",
    "    # Get all collected metrics\n",
    "    all_metrics = get_metrics().get_all_metrics()\n",
    "    \n",
    "    # Get all collected logs\n",
    "    logs = log_stream.getvalue()\n",
    "    \n",
    "    return logs, all_metrics, consumer.received_messages\n",
    "\n",
    "logs_raw, metrics_raw, consumed_messages = run_simulation_and_collect_data(num_messages=200, capacity=5)\n",
    "\n",
    "print(f\"\\nTotal consumed messages: {len(consumed_messages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2609f95c",
   "metadata": {},
   "source": [
    "## 5. Analyzing Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093bb9cd",
   "metadata": {},
   "source": [
    "We'll parse the raw JSON logs into a Pandas DataFrame for easier filtering and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ebc6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_lines = logs_raw.strip().split('\\n')\n",
    "log_data = [json.loads(line) for line in log_lines if line.strip()]\n",
    "logs_df = pd.DataFrame(log_data)\n",
    "\n",
    "# Convert timestamp to datetime for better readability\n",
    "logs_df['ts_datetime'] = pd.to_datetime(logs_df['ts'], unit='s')\n",
    "\n",
    "print(\"Sample Log Entries:\")\n",
    "display(logs_df.head())\n",
    "\n",
    "# Filter logs for specific events, e.g., message processing\n",
    "message_processing_logs = logs_df[logs_df['event'] == 'processing.start']\n",
    "print(\"\\nSample Message Processing Logs:\")\n",
    "display(message_processing_logs.head())\n",
    "\n",
    "# You can further filter by node, port, message_type, etc.\n",
    "producer_emits = logs_df[(logs_df['node'] == 'producer') & (logs_df['event'] == 'scheduler.message_put_result')]\n",
    "print(\"\\nSample Producer Emit Results:\")\n",
    "display(producer_emits.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eb5f33",
   "metadata": {},
   "source": [
    "## 6. Analyzing Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973d782d",
   "metadata": {},
   "source": [
    "We'll extract relevant metrics and visualize them over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20519279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract queue depth metrics\n",
    "queue_depth_metrics = []\n",
    "for metric_name, metric_data in metrics_raw.items():\n",
    "    if metric_name.startswith('demo_app_edge_queue_depth'):\n",
    "        for timestamp, value in metric_data['values']:\n",
    "            labels = metric_data['labels']\n",
    "            queue_depth_metrics.append({\n",
    "                'timestamp': timestamp,\n",
    "                'value': value,\n",
    "                'edge_id': labels.get('edge_id', 'unknown')\n",
    "            })\n",
    "\n",
    "queue_depth_df = pd.DataFrame(queue_depth_metrics)\n",
    "queue_depth_df['timestamp'] = pd.to_datetime(queue_depth_df['timestamp'], unit='s')\n",
    "\n",
    "if not queue_depth_df.empty:\n",
    "    fig = px.line(queue_depth_df, x='timestamp', y='value', color='edge_id', title='Queue Depth Over Time')\n",
    "    fig.update_layout(yaxis_title='Queue Depth')\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No queue depth metrics to display.\")\n",
    "\n",
    "# Extract message processing rates (example using counter deltas)\n",
    "# This is a simplified example; for true rates, you'd typically use Prometheus rate queries.\n",
    "message_counts = []\n",
    "for metric_name, metric_data in metrics_raw.items():\n",
    "    if metric_name.startswith('demo_app_node_messages_total'):\n",
    "        for timestamp, value in metric_data['values']:\n",
    "            labels = metric_data['labels']\n",
    "            message_counts.append({\n",
    "                'timestamp': timestamp,\n",
    "                'value': value,\n",
    "                'node': labels.get('node', 'unknown')\n",
    "            })\n",
    "\n",
    "message_counts_df = pd.DataFrame(message_counts)\n",
    "message_counts_df['timestamp'] = pd.to_datetime(message_counts_df['timestamp'], unit='s')\n",
    "\n",
    "if not message_counts_df.empty:\n",
    "    # Calculate rate as difference between consecutive values for each node\n",
    "    message_rates_df = message_counts_df.sort_values(by=['node', 'timestamp'])\n",
    "    message_rates_df['rate'] = message_rates_df.groupby('node')['value'].diff().fillna(0)\n",
    "    \n",
    "    fig = px.line(message_rates_df, x='timestamp', y='rate', color='node', title='Message Processing Rate')\n",
    "    fig.update_layout(yaxis_title='Messages Processed per Tick')\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No message processing metrics to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e91ffe5",
   "metadata": {},
   "source": [
    "## 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38ba9bc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "This notebook provides a foundation for analyzing observability data from Meridian Runtime. By combining structured logging with metrics, you can gain deep insights into your dataflow's performance and behavior."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
