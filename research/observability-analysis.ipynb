{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd326ec",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fcbd47e",
   "metadata": {},
   "source": [
    "---\n",
    "jupyter:\n",
    "  jupytext:\n",
    "    text_representation:\n",
    "      extension: .py\n",
    "      format_name: light\n",
    "      format_version: '1.5'\n",
    "      jupytext_version: 1.17.2\n",
    "  kernelspec:\n",
    "    display_name: Python 3\n",
    "    name: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0d5d0f",
   "metadata": {},
   "source": [
    "# Observability Analysis with Meridian Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0320c3cc",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to capture, filter, and analyze observability data (logs and metrics) from Meridian Runtime. It showcases how to gain insights into the behavior of your dataflows using structured logging and Prometheus-style metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d121cc5",
   "metadata": {},
   "source": [
    "## 1. Setup: Add Project to Python Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3509889e",
   "metadata": {},
   "source": [
    "This cell adds the project's `src` directory to the Python path. This is necessary for the notebook to find and import the `meridian` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93ea68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's 'src' directory to the Python path\n",
    "# This is necessary for the notebook to find the 'meridian' module\n",
    "# We assume the notebook is run from the 'notebooks/research' directory.\n",
    "src_path = os.path.abspath('../../src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "    print(f\"Added '{src_path}' to the Python path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b582580c",
   "metadata": {},
   "source": [
    "## 2. Imports and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49588f77",
   "metadata": {},
   "source": [
    "We'll import necessary modules and configure observability to capture logs and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef7b06",
   "metadata": {
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import time\n",
    "import threading\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display\n",
    "\n",
    "from meridian.core import Node, Message, MessageType, Port, PortDirection, PortSpec, Subgraph, Scheduler, SchedulerConfig\n",
    "from meridian.observability.config import ObservabilityConfig, configure_observability\n",
    "from meridian.observability.logging import get_logger\n",
    "from meridian.observability.metrics import PrometheusMetrics, configure_metrics, get_metrics\n",
    "\n",
    "# Use an in-memory stream to capture logs\n",
    "log_stream = io.StringIO()\n",
    "\n",
    "# Configure observability to capture logs and metrics\n",
    "configure_observability(\n",
    "    ObservabilityConfig(\n",
    "        log_level=\"DEBUG\", # Capture all logs for analysis\n",
    "        log_json=True,     # Emit JSON logs for easy parsing\n",
    "        log_stream=log_stream,\n",
    "        metrics_enabled=True,\n",
    "        metrics_namespace=\"demo_app\",\n",
    "        tracing_enabled=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Ensure PrometheusMetrics is configured for metric collection\n",
    "configure_metrics(PrometheusMetrics())\n",
    "\n",
    "logger = get_logger()\n",
    "metrics = get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06833fcf",
   "metadata": {},
   "source": [
    "## 3. Graph Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfa7154",
   "metadata": {},
   "source": [
    "We'll define a simple graph with a producer, a processing node, and a consumer to generate observability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d86b924",
   "metadata": {
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class DataProducer(Node):\n",
    "    def __init__(self, n=100):\n",
    "        super().__init__(\n",
    "            name=\"producer\",\n",
    "            inputs=[],\n",
    "            outputs=[Port(\"out\", PortDirection.OUTPUT, spec=PortSpec(\"out\", int))],\n",
    "        )\n",
    "        self._n = n\n",
    "        self._i = 0\n",
    "\n",
    "    def _handle_tick(self):\n",
    "        if self._i < self._n:\n",
    "            self.emit(\"out\", Message(type=MessageType.DATA, payload=self._i))\n",
    "            self._i += 1\n",
    "\n",
    "class DataProcessor(Node):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"processor\",\n",
    "            inputs=[Port(\"in\", PortDirection.INPUT, spec=PortSpec(\"in\", int))],\n",
    "            outputs=[Port(\"out\", PortDirection.OUTPUT, spec=PortSpec(\"out\", int))],\n",
    "        )\n",
    "\n",
    "    def _handle_message(self, port, msg):\n",
    "        # Simulate some processing time\n",
    "        time.sleep(0.005)\n",
    "        self.emit(\"out\", Message(type=MessageType.DATA, payload=msg.payload * 2))\n",
    "\n",
    "class DataConsumer(Node):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"consumer\",\n",
    "            inputs=[Port(\"in\", PortDirection.INPUT, spec=PortSpec(\"in\", int))],\n",
    "            outputs=[],\n",
    "        )\n",
    "        self.received_messages = []\n",
    "\n",
    "    def _handle_message(self, port, msg):\n",
    "        self.received_messages.append(msg.payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745681c9",
   "metadata": {},
   "source": [
    "## 4. Running the Simulation and Collecting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd40dc",
   "metadata": {},
   "source": [
    "We'll run the graph and collect all logs and metrics generated during its execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc30cd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualizingScheduler(Scheduler):\n",
    "    def __init__(self, config: SchedulerConfig | None = None):\n",
    "        super().__init__(config)\n",
    "        self.queue_depth_history = {}\n",
    "        self.message_counts_history = {}\n",
    "        self.timestamps = []\n",
    "        self._start_time = time.monotonic()\n",
    "\n",
    "    def _run_main_loop(self) -> None:\n",
    "        # Call the original main loop, but also collect metrics periodically\n",
    "        loop_start_time = time.monotonic()\n",
    "        last_metric_collection_time = loop_start_time\n",
    "        \n",
    "        while not self._shutdown:\n",
    "            # Collect metrics snapshot\n",
    "            current_time = time.monotonic() - self._start_time\n",
    "            self.timestamps.append(current_time)\n",
    "\n",
    "            # Collect queue depths\n",
    "            for edge_ref in self._plan.edges.values():\n",
    "                edge_id = edge_ref.edge._edge_id()\n",
    "                if edge_id not in self.queue_depth_history:\n",
    "                    self.queue_depth_history[edge_id] = []\n",
    "                self.queue_depth_history[edge_id].append(edge_ref.edge.depth())\n",
    "\n",
    "            # Collect message counts (counters)\n",
    "            for metric_key, counter_obj in metrics.get_all_counters().items():\n",
    "                if metric_key.startswith('demo_app_node_messages_total'):\n",
    "                    node_name = counter_obj._labels.get('node', 'unknown')\n",
    "                    if node_name not in self.message_counts_history:\n",
    "                        self.message_counts_history[node_name] = []\n",
    "                    self.message_counts_history[node_name].append(counter_obj.value)\n",
    "\n",
    "            # Run a single iteration of the scheduler's main loop logic\n",
    "            super()._run_main_loop_single_iteration() # Assuming such a method exists or can be extracted\n",
    "\n",
    "            # Sleep to control loop frequency and allow time for external events\n",
    "            sleep_time = self._cfg.tick_interval_ms / 1000.0\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "        # Ensure all history lists have the same length for plotting\n",
    "        max_len = max(len(q) for q in self.queue_depth_history.values())\n",
    "        for q in self.queue_depth_history.values():\n",
    "            while len(q) < max_len:\n",
    "                q.append(q[-1] if q else 0) # Pad with last value or 0\n",
    "\n",
    "        max_len = max(len(q) for q in self.message_counts_history.values())\n",
    "        for q in self.message_counts_history.values():\n",
    "            while len(q) < max_len:\n",
    "                q.append(q[-1] if q else 0) # Pad with last value or 0\n",
    "\n",
    "def run_simulation_and_collect_data(num_messages=100, capacity=10):\n",
    "    # Clear previous logs\n",
    "    log_stream.seek(0)\n",
    "    log_stream.truncate(0)\n",
    "\n",
    "    producer = DataProducer(n=num_messages)\n",
    "    processor = DataProcessor()\n",
    "    consumer = DataConsumer()\n",
    "\n",
    "    sg = Subgraph.from_nodes(\"observability_demo\", [producer, processor, consumer])\n",
    "    sg.connect((\"producer\", \"out\"), (\"processor\", \"in\"), capacity=capacity)\n",
    "    sg.connect((\"processor\", \"out\"), (\"consumer\", \"in\"), capacity=capacity)\n",
    "\n",
    "    scheduler = VisualizingScheduler(SchedulerConfig(tick_interval_ms=1, shutdown_timeout_s=10.0))\n",
    "    scheduler.register(sg)\n",
    "\n",
    "    print(\"🚀 Running simulation and collecting data...\")\n",
    "    scheduler.run()\n",
    "    print(\"Simulation finished.\")\n",
    "\n",
    "    # Get all collected metrics from the VisualizingScheduler\n",
    "    metrics_raw = {\n",
    "        \"queue_depth_history\": scheduler.queue_depth_history,\n",
    "        \"message_counts_history\": scheduler.message_counts_history,\n",
    "        \"timestamps\": scheduler.timestamps,\n",
    "    }\n",
    "    \n",
    "    # Get all collected logs\n",
    "    logs = log_stream.getvalue()\n",
    "    \n",
    "    return logs, metrics_raw, consumer.received_messages\n",
    "\n",
    "logs_raw, metrics_raw, consumed_messages = run_simulation_and_collect_data(num_messages=200, capacity=5)\n",
    "\n",
    "print(f\"\\nTotal consumed messages: {len(consumed_messages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cadb66",
   "metadata": {},
   "source": [
    "## 5. Analyzing Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aed716",
   "metadata": {},
   "source": [
    "We'll parse the raw JSON logs into a Pandas DataFrame for easier filtering and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebcd770",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_lines = logs_raw.strip().split('\\n')\n",
    "log_data = [json.loads(line) for line in log_lines if line.strip()]\n",
    "logs_df = pd.DataFrame(log_data)\n",
    "\n",
    "# Convert timestamp to datetime for better readability\n",
    "logs_df['ts_datetime'] = pd.to_datetime(logs_df['ts'], unit='s')\n",
    "\n",
    "print(\"Sample Log Entries:\")\n",
    "display(logs_df.head())\n",
    "\n",
    "# Filter logs for specific events, e.g., message processing\n",
    "message_processing_logs = logs_df[logs_df['event'] == 'processing.start']\n",
    "print(\"\\nSample Message Processing Logs:\")\n",
    "display(message_processing_logs.head())\n",
    "\n",
    "# You can further filter by node, port, message_type, etc.\n",
    "producer_emits = logs_df[(logs_df['node'] == 'producer') & (logs_df['event'] == 'scheduler.message_put_result')]\n",
    "print(\"\\nSample Producer Emit Results:\")\n",
    "display(producer_emits.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72539a0f",
   "metadata": {},
   "source": [
    "## 6. Analyzing Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aee231d",
   "metadata": {},
   "source": [
    "We'll extract relevant metrics and visualize them over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f5b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract queue depth metrics\n",
    "queue_depth_metrics = []\n",
    "if 'queue_depth_history' in metrics_raw and 'timestamps' in metrics_raw:\n",
    "    timestamps = metrics_raw['timestamps']\n",
    "    for edge_id, history in metrics_raw['queue_depth_history'].items():\n",
    "        for i, value in enumerate(history):\n",
    "            queue_depth_metrics.append({\n",
    "                'timestamp': timestamps[i],\n",
    "                'value': value,\n",
    "                'edge_id': edge_id\n",
    "            })\n",
    "\n",
    "queue_depth_df = pd.DataFrame(queue_depth_metrics)\n",
    "queue_depth_df['timestamp'] = pd.to_datetime(queue_depth_df['timestamp'], unit='s')\n",
    "\n",
    "if not queue_depth_df.empty:\n",
    "    fig = px.line(queue_depth_df, x='timestamp', y='value', color='edge_id', title='Queue Depth Over Time')\n",
    "    fig.update_layout(yaxis_title='Queue Depth')\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No queue depth metrics to display.\")\n",
    "\n",
    "# Extract message processing rates\n",
    "message_counts = []\n",
    "if 'message_counts_history' in metrics_raw and 'timestamps' in metrics_raw:\n",
    "    timestamps = metrics_raw['timestamps']\n",
    "    for node_name, history in metrics_raw['message_counts_history'].items():\n",
    "        for i, value in enumerate(history):\n",
    "            message_counts.append({\n",
    "                'timestamp': timestamps[i],\n",
    "                'value': value,\n",
    "                'node': node_name\n",
    "            })\n",
    "\n",
    "message_counts_df = pd.DataFrame(message_counts)\n",
    "message_counts_df['timestamp'] = pd.to_datetime(message_counts_df['timestamp'], unit='s')\n",
    "\n",
    "if not message_counts_df.empty:\n",
    "    # Calculate rate as difference between consecutive values for each node\n",
    "    message_rates_df = message_counts_df.sort_values(by=['node', 'timestamp'])\n",
    "    message_rates_df['rate'] = message_rates_df.groupby('node')['value'].diff().fillna(0)\n",
    "    \n",
    "    fig = px.line(message_rates_df, x='timestamp', y='rate', color='node', title='Message Processing Rate')\n",
    "    fig.update_layout(yaxis_title='Messages Processed per Tick')\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No message processing metrics to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7a0842",
   "metadata": {},
   "source": [
    "## 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deedcd9",
   "metadata": {},
   "source": [
    "This notebook provides a foundation for analyzing observability data from Meridian Runtime. By combining structured logging with metrics, you can gain deep insights into your dataflow's performance and behavior."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
